{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realign two EEGLab.Epoch object's epochs.\n",
    "\n",
    "@Author [@FranckPrts](hstate_dictps://github.com/FranckPrts).\n",
    "\n",
    "Here we astate_dictempt to provide a python-based solution to the following question: **How to can I realign concurrent epochs from two epoched object?**\n",
    "\n",
    "Our main goal here is to be able to target all epochs in a given EEG that doesn't have a *sister* (concurently recorded) epoch in the other EEG because it was rejected by preprocessing. At the end, we should have two epoched EEG with the same amount of epochs and where each pair of epoch has their *sister* epoch at the same index.\n",
    "\n",
    "Fist, the EEG data of each participant was segmented in 1sec epochs before moving on to preprocessing independelty each two EEG data. For each stage of this iterative process (in our case 2-3 iterations) the ID of the rejected epochs were noted in a separate file.\n",
    "\n",
    "Our issue arise from the fact that once each step was performed, saving the data would lead to losing track of what was the epochs original IDs. \n",
    "As exemplified below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that process we see that an epoch that originally had the ID #6 can end up with the new ID #3. \n",
    "\n",
    "To retrieve the original id of the epoch, we will have to work bakward from the last iteration of preprocessing to the first iteration. At each step we will store what was the previous ID of the epochs so we can find their original IDs. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package \n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "# Custom functions\n",
    "import utils\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import two eeg stream that were preprocessed in MATLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EpochsEEGLAB_to_mneEpochsFIF (path):\n",
    "    \"\"\"\n",
    "    Loads a SET file into a mne.io.eeglab.eeglab.EpochsEEGLAB object\n",
    "    and converts it into a mne.Epochs instance.\n",
    "\n",
    "    Arguments\n",
    "    ----------\n",
    "    path: str\n",
    "        participant #1 fNIRS data path (directory)\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    mneEpochs:\n",
    "        instance of mne.Epochs.\n",
    "    \"\"\"\n",
    "    # read the file and get a mne.io.eeglab.eeglab.EpochsEEGLAB instance\n",
    "    tmp = mne.io.read_epochs_eeglab(path)\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        # save it in FIF\n",
    "        tmp.save(tmpdir+\"tmp.fif\", overwrite=True, verbose=None)\n",
    "        \n",
    "    # re-read it so it is now a mne.EpochsFIF\n",
    "    return mne.read_epochs(tmpdir+\"tmp.fif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_process = np.loadtxt(\"files_to_process.csv\",\n",
    "                 delimiter=\",\", dtype=str)\n",
    "\n",
    "dyad = [x for x in files_to_process]\n",
    "# Careful, the file_to_process is in the order (dyad_nb, eeg_filepath_child, eeg_filepath_adutl)\n",
    "dy = dyad[0]\n",
    "data_path = '../FINS-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/../FINS-data/220_child_FP/FINS_220_Child_FreePlay_xchan_rej3.set...\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Reading /var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpwntk963btmp.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     998.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Extracting parameters from /Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/../FINS-data/220_adult_FP/FINS_220_Adult_FreePlay_xchan_ica_rej3.set...\n",
      "Not setting metadata\n",
      "206 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Reading /var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmp31cajzmwtmp.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     998.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/ipykernel_23524/2622221197.py:17: RuntimeWarning: At least one epoch has multiple events. Only the latency of the first event will be retained.\n",
      "  tmp = mne.io.read_epochs_eeglab(path)\n",
      "/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/ipykernel_23524/2622221197.py:21: RuntimeWarning: This filename (/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpwntk963btmp.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  tmp.save(tmpdir+\"tmp.fif\", overwrite=True, verbose=None)\n",
      "/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/ipykernel_23524/2622221197.py:24: RuntimeWarning: This filename (/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpwntk963btmp.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  return mne.read_epochs(tmpdir+\"tmp.fif\")\n",
      "/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/ipykernel_23524/2622221197.py:17: RuntimeWarning: At least one epoch has multiple events. Only the latency of the first event will be retained.\n",
      "  tmp = mne.io.read_epochs_eeglab(path)\n",
      "/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/ipykernel_23524/2622221197.py:21: RuntimeWarning: This filename (/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmp31cajzmwtmp.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  tmp.save(tmpdir+\"tmp.fif\", overwrite=True, verbose=None)\n",
      "/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/ipykernel_23524/2622221197.py:24: RuntimeWarning: This filename (/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmp31cajzmwtmp.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  return mne.read_epochs(tmpdir+\"tmp.fif\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "206 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "eeg1 = EpochsEEGLAB_to_mneEpochsFIF('{}{}_{}_FP/{}'.format(data_path, dy[0], 'child', dy[1])) \n",
    "eeg2 = EpochsEEGLAB_to_mneEpochsFIF('{}{}_{}_FP/{}'.format(data_path, dy[0], 'adult', dy[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many epochs we have per EEG file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG-1 has 159 epochs.\n",
      "EEG-2 has 206 epochs.\n"
     ]
    }
   ],
   "source": [
    "print('EEG-1 has {} epochs.'.format(eeg1.get_data().shape[0]))\n",
    "print('EEG-2 has {} epochs.'.format(eeg2.get_data().shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, there should be the same amount of epochs in each file. Moreover, when looking at the index of each epochs (see the x-axis of the plots bellow) we can see that they are all continuous, thus, not indicating which epochs were rejected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg1.to_data_frame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the plan now?\n",
    "\n",
    "When loading an file in the EEGLAB format,  You have the following epoch indexes in your preprocessed file: \n",
    "\n",
    "`1, 2, 3, 4, 5, 6, 7`\n",
    "\n",
    "And you know that the following epochs were rejected:\n",
    "\n",
    "`3, 7, 8`\n",
    "\n",
    "but then get \n",
    "\n",
    "`1, 2, 3, 4`\n",
    "\n",
    "We'll now reconstruct the original epoch index as follows? (Within brackets):\n",
    "\n",
    "`1(1), 2(2), NaN, 4(3), 5(4), 6(5), NaN, NaN, 9(6), 10(7)`\n",
    "\n",
    "\n",
    "> **Careful, we have multiple round of rejection, so that method will have to be iterated over each round.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the epoch data\n",
    "\n",
    "We're now going to extract the epoch data from the mne.EpochFIF to apply the operation described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = eeg1.to_data_frame()\n",
    "df2 = eeg2.to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.epoch.unique()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letters</th>\n",
       "      <th>Indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letters  Indexes\n",
       "0       A        0\n",
       "1       B        1\n",
       "2       C        2\n",
       "3       D        3\n",
       "4       E        4\n",
       "5       F        5\n",
       "6       G        6\n",
       "7       H        7"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Letters': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'], 'Indexes': [0, 1, 2, 3, 4, 5, 6, 7]})\n",
    "\n",
    "# pd.set_option('display.max_rows', len(state_dict))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letters</th>\n",
       "      <th>Indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letters  Indexes\n",
       "0       A        0\n",
       "2       C        2\n",
       "4       E        4\n",
       "5       F        5\n",
       "6       G        6\n",
       "7       H        7"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we remove two rows in a first round:\n",
    "# Create a list of elements to remove\n",
    "rmed_1 = [1, 3]\n",
    "\n",
    "# Create a boolean mask indicating which rows to keep\n",
    "mask = df['Indexes'].isin(rmed_1)\n",
    "\n",
    "# Remove the rows that match the elements in the list\n",
    "df.drop(index=df[mask].index, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letters</th>\n",
       "      <th>Indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letters  Indexes\n",
       "0       A        0\n",
       "2       C        1\n",
       "4       E        2\n",
       "5       F        3\n",
       "6       G        4\n",
       "7       H        5"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we reset the index the same way saving this 'eeg' file would when being read for the next iteration's round \n",
    "df.Indexes = [i for i in range(len(df))]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letters</th>\n",
       "      <th>Indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letters  Indexes\n",
       "2       C        0\n",
       "5       F        1\n",
       "6       G        2"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now were remove three rows and directly reset the indexes\n",
    "# Create a list of elements to remove\n",
    "rmed_2 = [2, 5, 0]\n",
    "\n",
    "# Create a boolean mask indicating which rows to keep\n",
    "mask = df['Indexes'].isin(rmed_2)\n",
    "\n",
    "# Remove the rows that match the elements in the list\n",
    "df.drop(index=df[mask].index, inplace=True)\n",
    "\n",
    "df.Indexes = [i for i in range(len(df))]\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alrigth, now we have two list containning the indexes that were removed **`at the time of their round of rejection`**. \n",
    "\n",
    "Keep in mind that the index #4 could be deleted in multiple round as #4 could be reassigned when the file is re-read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index that were rejected at the\n",
      "\t1st round: [1, 3]\n",
      "\t2st round: [2, 5, 0]\n",
      "The indexes as they are after the last rejection round [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "last_state = df['Indexes'].tolist()\n",
    "print('Index that were rejected at the\\n\\t1st round: {}\\n\\t2st round: {}'.format(rmed_1, rmed_2))\n",
    "print('The indexes as they are after the last rejection round {}'.format(last_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_state_dict (last_state=list):\n",
    "    state_dict = {}\n",
    "    for i in last_state:\n",
    "        state_dict[i] = i\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_one_step_back (state_dict=dict, rm_idx=list, first_round_bool=bool) :\n",
    "    \n",
    "    # If this is the first round (i.e., the last rejection round)\n",
    "    if first_round_bool: \n",
    "        # Order the keys of the state_dict so we can iterate over them     \n",
    "        existing_states = []\n",
    "        for key in state_dict.keys():\n",
    "            existing_states.append(key)\n",
    "        existing_states.sort()\n",
    "\n",
    "        # Add placeholders in the state_dict for the new state\n",
    "        # added by introducing the removed states\n",
    "        for new_key in range(len(rm_idx)):\n",
    "            state_dict[existing_states[-1]+new_key+1] = existing_states[-1]+new_key+1\n",
    "\n",
    "        # Order the keys of the state_dict so we can iterate over them \n",
    "        existing_states = []\n",
    "        for key in state_dict.keys():\n",
    "            existing_states.append(key)\n",
    "        existing_states.sort()\n",
    "    else:\n",
    "\n",
    "\n",
    "    # Sort the states that were removed so we make sure we start by the \n",
    "    # lowest idx to reiterate shifting idx correctly\n",
    "    rm_idx.sort()\n",
    "\n",
    "    # For each index that was removed,\n",
    "    for rmed in rm_idx:\n",
    "        # Check all existing idx, and if the index\n",
    "        # already exist, update it such that ...\n",
    "        for existing in existing_states:\n",
    "            # ... only the indexes that would be shifted by introducing \n",
    "            # a NaN sees their 'new' index substracted 1.\n",
    "            # We substract 1 because in the persepctive of the initial df,\n",
    "            # the index of a given state lost a rank because of removing a\n",
    "            # state that was anterior to it.\n",
    "            if existing > rmed:\n",
    "                state_dict[existing] -= 1\n",
    "        state_dict[rmed] = 'NaN'\n",
    "\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the last state\n",
    "last_state=[0, 1, 2]\n",
    "\n",
    "# Define the \n",
    "rmed_list=[[2, 5, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state:\n",
      "\t 0 0\n",
      "\t 1 1\n",
      "\t 2 2\n",
      "Updated state:\n",
      "\t 0 NaN\n",
      "\t 1 0\n",
      "\t 2 NaN\n",
      "\t 3 1\n",
      "\t 4 2\n",
      "\t 5 NaN\n"
     ]
    }
   ],
   "source": [
    "# First initialise the state dict containing the true idx as keys \n",
    "# and their corresponding \n",
    "state_dict = create_initial_state_dict(last_state=last_state)\n",
    "print('Initial state:')\n",
    "for i in state_dict.keys():\n",
    "    print('\\t',i, state_dict[i])\n",
    "\n",
    "first_round_bool = True\n",
    "for rm_idx in rmed_list:\n",
    "    updated_state_dict = take_one_step_back(state_dict=state_dict, rm_idx=rm_idx, is_first=first_round_bool)\n",
    "    print('Updated state:')\n",
    "    for i in updated_state_dict.keys():\n",
    "        print('\\t',i, updated_state_dict[i])\n",
    "    first_round_bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful references"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To get comfortable with the MNE documentation, you should know that MNE is based on python [Object Oriented Programming (00P)](hstate_dictps://realpython.com/python3-object-oriented-programming/). These objects are defined from a python `Class`.\n",
    "    - You can get familiarized with the OOP structure and its componenent, e.g. `methods` (a function associated to the the object) and `astate_dictribute` (a variable associated to the object), wit [this tutorial](hstate_dictps://www.datacamp.com/tutorial/python-oop-tutorial).\n",
    "    - In MNE, we find [`Raw` objects](hstate_dictps://mne.tools/stable/generated/mne.io.Raw.html) (continuous data) or [`Epoch` objects](hstate_dictps://mne.tools/stable/generated/mne.Epochs.html) (a collection of epochs). \n",
    "\n",
    "You can find an introduction to the **Epochs data structure** [here](hstate_dictps://mne.tools/stable/auto_tutorials/epochs/10_epochs_overview.html) in MNE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d93afb8cdc34b2bdea5bf079bccd93013ea04d457e334f9ae90fb664fbdee86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
