{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realign two EEGLab.Epoch object's epochs.\n",
    "\n",
    "@Author [@FranckPrts](hstate_dictps://github.com/FranckPrts).\n",
    "\n",
    "Here we provide a python-based solution to **realign concurrent epochs contained in two epoched object that lost their alignement because of losing their concurrence during preprocessing.**\n",
    "\n",
    "After procedding to preprocessing in EEGLAB, the data were saved in `.set` format. When later loading this data, the \n",
    "\n",
    "Our main goal here is to remove epochs in a given EEG that should have been removed during preprocessing when the concurent epoch in the other EEG was. At the end, we should have two epoched EEG with the same amount of epochs and where each epoch at a given index correspond what was curcurent while recording.\n",
    "\n",
    "As exemplified below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#IMAGE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things that might be idiosynchratic:\n",
    "\n",
    "1. Our EEG data was segmented in 1sec epochs (which helps with congruency between epochs and the time they where collected).\n",
    "2. Preprocessing was done independelty for each EEG data. \n",
    "3. Each dyad were preprocessed 2-3 times (iteration).\n",
    "    - epochs ID that were rejected were noted in a separate file between each round.\n",
    "    - the objects were save at the end of each iteration and re-read after so .\n",
    "\n",
    "Our issue arise from the fact that once each step was performed, saving the data would lead to losing track of what was the epochs original IDs. \n",
    "\n",
    "In that process we see that an epoch that originally had the ID #6 can end up with the new ID #3. \n",
    "\n",
    "To retrieve the original id of the epoch, we will have to work bakward from the last iteration of preprocessing to the first iteration. At each step we will store what was the previous ID of the epochs so we can find their original IDs. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package \n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Custom functions\n",
    "from utils import align_utils\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import two eeg stream that were preprocessed in MATLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_process = np.loadtxt(\"files_to_process.csv\",\n",
    "                 delimiter=\",\", dtype=str)\n",
    "\n",
    "dyad = [x for x in files_to_process]\n",
    "# Careful, the file_to_process is in the order (dyad_nb, eeg_filepath_child, eeg_filepath_adutl)\n",
    "dy = dyad[0]\n",
    "data_path = '../FINS-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/../FINS-data/220_child_FP/FINS_220_Child_FreePlay_xchan_rej3.set...\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Reading /var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpvagbk3f8tmp.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     998.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Extracting parameters from /Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/../FINS-data/220_adult_FP/FINS_220_Adult_FreePlay_xchan_ica_rej3.set...\n",
      "Not setting metadata\n",
      "206 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/utils/align_utils.py:22: RuntimeWarning: At least one epoch has multiple events. Only the latency of the first event will be retained.\n",
      "  tmp = mne.io.read_epochs_eeglab(path)\n",
      "/Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/utils/align_utils.py:26: RuntimeWarning: This filename (/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpvagbk3f8tmp.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  tmp.save(tmpdir+\"tmp.fif\", overwrite=True, verbose=None)\n",
      "/Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/utils/align_utils.py:29: RuntimeWarning: This filename (/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpvagbk3f8tmp.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  return mne.read_epochs(tmpdir+\"tmp.fif\")\n",
      "/Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/utils/align_utils.py:22: RuntimeWarning: At least one epoch has multiple events. Only the latency of the first event will be retained.\n",
      "  tmp = mne.io.read_epochs_eeglab(path)\n",
      "/Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/utils/align_utils.py:26: RuntimeWarning: This filename (/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpdxl72z3vtmp.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  tmp.save(tmpdir+\"tmp.fif\", overwrite=True, verbose=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpdxl72z3vtmp.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     998.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "206 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/utils/align_utils.py:29: RuntimeWarning: This filename (/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpdxl72z3vtmp.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  return mne.read_epochs(tmpdir+\"tmp.fif\")\n"
     ]
    }
   ],
   "source": [
    "eeg1 = align_utils.EpochsEEGLAB_to_mneEpochsFIF('{}{}_{}_FP/{}'.format(data_path, dy[0], 'child', dy[1])) \n",
    "eeg2 = align_utils.EpochsEEGLAB_to_mneEpochsFIF('{}{}_{}_FP/{}'.format(data_path, dy[0], 'adult', dy[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many epochs we have per EEG file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG-1 has 159 epochs.\n",
      "EEG-2 has 206 epochs.\n"
     ]
    }
   ],
   "source": [
    "print('EEG-1 has {} epochs.'.format(eeg1.get_data().shape[0]))\n",
    "print('EEG-2 has {} epochs.'.format(eeg2.get_data().shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, there should be the same amount of epochs in each file. Moreover, when looking at the index of each epochs (see the x-axis of the plots bellow) we can see that they are all continuous, thus, not indicating which epochs were rejected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg2.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the plan now?\n",
    "\n",
    "When loading an file in the EEGLAB format,  You have the following epoch indexes in your preprocessed file: \n",
    "\n",
    "`1, 2, 3, 4, 5, 6, 7`\n",
    "\n",
    "And you know that the following epochs were rejected:\n",
    "\n",
    "`3, 7, 8`\n",
    "\n",
    "but then get \n",
    "\n",
    "`1, 2, 3, 4`\n",
    "\n",
    "We'll now reconstruct the original epoch index as follows? (Within brackets):\n",
    "\n",
    "`1(1), 2(2), NaN, 4(3), 5(4), 6(5), NaN, NaN, 9(6), 10(7)`\n",
    "\n",
    "\n",
    "> **Careful, we have multiple round of rejection, so that method will have to be iterated over each round.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = eeg1.to_data_frame()\n",
    "df2 = eeg2.to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eeg1epochsIDs = df1.epoch.unique()\n",
    "Eeg2epochsIDs = df2.epoch.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letters</th>\n",
       "      <th>Indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letters  Indexes\n",
       "0       A        0\n",
       "1       B        1\n",
       "2       C        2\n",
       "3       D        3\n",
       "4       E        4\n",
       "5       F        5\n",
       "6       G        6\n",
       "7       H        7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Letters': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'], 'Indexes': [0, 1, 2, 3, 4, 5, 6, 7]})\n",
    "\n",
    "# pd.set_option('display.max_rows', len(state_dict))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letters</th>\n",
       "      <th>Indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letters  Indexes\n",
       "0       A        0\n",
       "2       C        1\n",
       "4       E        2\n",
       "5       F        3\n",
       "6       G        4\n",
       "7       H        5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we remove two rows in a first round:\n",
    "# Create a list of elements to remove\n",
    "rmed_1 = [1, 3]\n",
    "\n",
    "# Create a boolean mask indicating which rows to keep\n",
    "mask = df['Indexes'].isin(rmed_1)\n",
    "\n",
    "# Remove the rows that match the elements in the list\n",
    "df.drop(index=df[mask].index, inplace=True)\n",
    "\n",
    "# Now we reset the index the same way saving this 'eeg' file would when being read for the next iteration's round \n",
    "df.Indexes = [i for i in range(len(df))]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letters</th>\n",
       "      <th>Indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letters  Indexes\n",
       "2       C        0\n",
       "5       F        1\n",
       "6       G        2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now were remove three rows and directly reset the indexes\n",
    "# Create a list of elements to remove\n",
    "rmed_2 = [2, 5, 0]\n",
    "\n",
    "# Create a boolean mask indicating which rows to keep\n",
    "mask = df['Indexes'].isin(rmed_2)\n",
    "\n",
    "# Remove the rows that match the elements in the list\n",
    "df.drop(index=df[mask].index, inplace=True)\n",
    "\n",
    "df.Indexes = [i for i in range(len(df))]\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alrigth, now we have two list containning the indexes that were removed **`at the time of their round of rejection`**. \n",
    "\n",
    "Keep in mind that the index #4 could be deleted in multiple round as #4 could be reassigned when the file is re-read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index that were rejected at the\n",
      "\t1st round: [1, 3]\n",
      "\t2st round: [2, 5, 0]\n",
      "The indexes as they are after the last rejection round [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "final_idx = df['Indexes'].tolist()\n",
    "print('Index that were rejected at the\\n\\t1st round: {}\\n\\t2st round: {}'.format(rmed_1, rmed_2))\n",
    "print('The indexes as they are after the last rejection round {}'.format(final_idx))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the list of epochs that were rejected as the `list` of `list` containing the IDs of the epochs that were rejected at each round of preprocessing. **The first `list` should contain the epochs IDs rejected at first preprocessing round and the last element should correspond to the last.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3], [2, 5, 0]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the list of epochs that were rejected\n",
    "rmed_list=[rmed_1, rmed_2]\n",
    "rmed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_initial_state_dict (final_idx=list):\n",
    "#     state_dict = {}\n",
    "#     for i in final_idx:\n",
    "#         state_dict[i] = i\n",
    "#     return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def take_a_step_back (state_dict=dict, rm_idx=list, is_first_round=bool) :\n",
    "    \n",
    "#     # If this is the first round (i.e., the last rejection round)\n",
    "#     if is_first_round: \n",
    "#         # Order the keys of the state_dict so we can iterate over them     \n",
    "#         existing_states = []\n",
    "#         for key in state_dict.keys():\n",
    "#             existing_states.append(key)\n",
    "#         existing_states.sort()\n",
    "\n",
    "#         # Add placeholders in the state_dict for the new state\n",
    "#         # added by introducing the removed states\n",
    "#         for new_key in range(len(rm_idx)):\n",
    "#             state_dict[existing_states[-1]+new_key+1] = existing_states[-1]+new_key+1\n",
    "\n",
    "#         # Order the keys of the state_dict so we can iterate over them \n",
    "#         existing_states = []\n",
    "#         for key in state_dict.keys():\n",
    "#             existing_states.append(key)\n",
    "#         existing_states.sort()\n",
    "#     else:\n",
    "#         existing_states = []\n",
    "#         for key in state_dict.keys():\n",
    "#             existing_states.append(key)\n",
    "#         existing_states.sort()\n",
    "\n",
    "#         # Find what is the highest values of a state that exist,\n",
    "#         # we'll need that to define the values of the states we're\n",
    "#         # adding correctly (e.g. if we have [0(0), 1(NaN), 2(1)], \n",
    "#         # we're adding the state #3 with value '2': [0(0), 1(NaN), 2(1), 3(2)])\n",
    "#         tmp = [state_dict[i] for i in state_dict.keys() if state_dict[i] != 'NaN']\n",
    "#         tmp.sort()\n",
    "#         highest_state_val = tmp[-1]\n",
    "#         del tmp\n",
    "\n",
    "#         # Add placeholders in the state_dict for the new state\n",
    "#         # added by introducing the removed states\n",
    "#         for new_key in range(len(rm_idx)):\n",
    "#             state_dict[existing_states[-1]+new_key+1] = highest_state_val+new_key+1\n",
    "\n",
    "#         existing_states = []\n",
    "#         for key in state_dict.keys():\n",
    "#             existing_states.append(key)\n",
    "#         existing_states.sort()\n",
    "\n",
    "#     # Sort the states that were removed so we make sure we start by the \n",
    "#     # lowest idx to reiterate shifting idx correctly\n",
    "#     rm_idx.sort()\n",
    "\n",
    "#     # For each index that was removed,\n",
    "#     for rmed in rm_idx:\n",
    "#         # Check all existing idx, and if the index\n",
    "#         # already exist, update it such that ...\n",
    "#         for existing in existing_states:\n",
    "#             # ... only the indexes that would be shifted by introducing \n",
    "#             # a NaN sees their 'new' index substracted 1.\n",
    "#             # We substract 1 because in the persepctive of the initial df,\n",
    "#             # the index of a given state lost a rank because of removing a\n",
    "#             # state that was anterior to it.\n",
    "#             if existing > rmed:\n",
    "#                 if state_dict[existing] == 'NaN':\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     state_dict[existing] -= 1\n",
    "#         state_dict[rmed] = 'NaN'\n",
    "\n",
    "#     return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def revert_to_original_idx (final_idx=list, rmed_list=list, verbose=True):\n",
    "    \n",
    "#     # First initialise the state dict containing the true idx as keys \n",
    "#     # and their corresponding epoch (here the letters)\n",
    "#     state_dict = create_initial_state_dict(final_idx)\n",
    "\n",
    "#     if verbose:\n",
    "#         print('Initial state:')\n",
    "#         for i in state_dict.keys():\n",
    "#             print('\\t',i, state_dict[i])\n",
    "\n",
    "#     # revert \"final_idx\" so we can beging by the last round \n",
    "#     final_idx.reverse()\n",
    "\n",
    "#     # Initialize the boolean \"first_round_bool\" to be true so the \n",
    "#     # function knows it has to take the special step it needs to \n",
    "#     # for \n",
    "#     first_round_bool = True\n",
    "    \n",
    "#     for rm_idx in rmed_list:\n",
    "\n",
    "#         updated_state_dict = take_a_step_back(\n",
    "#             state_dict=state_dict, \n",
    "#             rm_idx=rm_idx, \n",
    "#             is_first_round=first_round_bool)\n",
    "        \n",
    "#         if verbose:\n",
    "#             print('Updated state:')\n",
    "#             for i in updated_state_dict.keys():\n",
    "#                 print('\\t',i, updated_state_dict[i])\n",
    "            \n",
    "#         # Not the first round anymore\n",
    "#         first_round_bool = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state:\n",
      "\t 0 0\n",
      "\t 1 1\n",
      "\t 2 2\n",
      "Updated state:\n",
      "\t 0 NaN\n",
      "\t 1 0\n",
      "\t 2 NaN\n",
      "\t 3 1\n",
      "\t 4 2\n",
      "\t 5 NaN\n",
      "Updated state:\n",
      "\t 0 NaN\n",
      "\t 2 0\n",
      "\t 4 NaN\n",
      "\t 5 1\n",
      "\t 6 2\n",
      "\t 7 NaN\n",
      "\t 1 NaN\n",
      "\t 3 NaN\n"
     ]
    }
   ],
   "source": [
    "updated_state_dict = align_utils.revert_to_original_idx(\n",
    "    last_state = final_idx,\n",
    "    removed_list  = rmed_list,\n",
    "    verbose    = True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that we reconstructed the correspondance between IDs and their original place correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tOriginal ID\tFinal state\tLetter\n",
      "\t 0 \t\t NaN \t\t A\n",
      "\t 1 \t\t NaN \t\t B\n",
      "\t 2 \t\t 0 \t\t C\n",
      "\t 3 \t\t NaN \t\t D\n",
      "\t 4 \t\t NaN \t\t E\n",
      "\t 5 \t\t 1 \t\t F\n",
      "\t 6 \t\t 2 \t\t G\n",
      "\t 7 \t\t NaN \t\t H\n"
     ]
    }
   ],
   "source": [
    "letters=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "\n",
    "tt = sorted(updated_state_dict.keys())\n",
    "\n",
    "print('\\tOriginal ID\\tFinal state\\tLetter',)\n",
    "for i in tt:\n",
    "    print('\\t',i,'\\t\\t',updated_state_dict[i],'\\t\\t', letters[i])\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dictionnary that has `keys` representing each of the original epoch ID and `values` representing the state of that epoch at the end of preprocessing.\n",
    "\n",
    "The **state** can be either\n",
    "- `NaN` which indicated that this epoch was removed during preprocessing **or,**\n",
    "- the id that was initially associated to the remaining epochs.\n",
    "\n",
    "Now that we have this for a subject EEG "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful references"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To get comfortable with the MNE documentation, you should know that MNE is based on python [Object Oriented Programming (00P)](hstate_dictps://realpython.com/python3-object-oriented-programming/). These objects are defined from a python `Class`.\n",
    "    - You can get familiarized with the OOP structure and its componenent, e.g. `methods` (a function associated to the the object) and `astate_dictribute` (a variable associated to the object), wit [this tutorial](hstate_dictps://www.datacamp.com/tutorial/python-oop-tutorial).\n",
    "    - In MNE, we find [`Raw` objects](hstate_dictps://mne.tools/stable/generated/mne.io.Raw.html) (continuous data) or [`Epoch` objects](hstate_dictps://mne.tools/stable/generated/mne.Epochs.html) (a collection of epochs). \n",
    "\n",
    "You can find an introduction to the **Epochs data structure** [here](hstate_dictps://mne.tools/stable/auto_tutorials/epochs/10_epochs_overview.html) in MNE. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the epoch data\n",
    "\n",
    "We're now going to extract the epoch data from the mne.EpochFIF to apply the operation described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d93afb8cdc34b2bdea5bf079bccd93013ea04d457e334f9ae90fb664fbdee86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
