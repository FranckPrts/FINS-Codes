{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realign two EEGLab.Epoch object's epochs.\n",
    "\n",
    "@Author [@FranckPrts](hstate_dictps://github.com/FranckPrts).\n",
    "\n",
    "Here we provide a python-based solution to **realign concurrent epochs contained in two epoched object that lost their alignement because of losing their concurrence during preprocessing.**\n",
    "\n",
    "After procedding to preprocessing in EEGLAB, the data were saved in `.set` format. When later loading this data, the \n",
    "\n",
    "Our main goal here is to remove epochs in a given EEG that should have been removed during preprocessing when the concurent epoch in the other EEG was. At the end, we should have two epoched EEG with the same amount of epochs and where each epoch at a given index correspond what was curcurent while recording.\n",
    "\n",
    "As exemplified below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#IMAGE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things that might be idiosynchratic:\n",
    "\n",
    "1. Our EEG data was segmented in 1sec epochs (which helps with congruency between epochs and the time they where collected).\n",
    "2. Preprocessing was done independelty for each EEG data. \n",
    "3. Each dyad were preprocessed 2-3 times (iteration).\n",
    "    - epochs ID that were rejected were noted in a separate file between each round.\n",
    "    - the objects were save at the end of each iteration and re-read after so .\n",
    "\n",
    "Our issue arise from the fact that once each step was performed, saving the data would lead to losing track of what was the epochs original IDs. \n",
    "\n",
    "In that process we see that an epoch that originally had the ID #6 can end up with the new ID #3. \n",
    "\n",
    "To retrieve the original id of the epoch, we will have to work bakward from the last iteration of preprocessing to the first iteration. At each step we will store what was the previous ID of the epochs so we can find their original IDs. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package \n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Custom functions\n",
    "from utils import align_utils\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import two eeg stream that were preprocessed in MATLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_process = np.loadtxt(\"files_to_process.csv\",\n",
    "                 delimiter=\",\", dtype=str)\n",
    "\n",
    "dyad = [x for x in files_to_process]\n",
    "# Careful, the file_to_process is in the order (dyad_nb, eeg_filepath_child, eeg_filepath_adutl)\n",
    "dy = dyad[0]\n",
    "data_path = '../FINS-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/../FINS-data/220_child_FP/FINS_220_Child_FreePlay_xchan_rej3.set...\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Reading /var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpo57y3cm1tmp.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     998.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "159 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Extracting parameters from /Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/../FINS-data/220_adult_FP/FINS_220_Adult_FreePlay_xchan_ica_rej3.set...\n",
      "Not setting metadata\n",
      "206 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/utils/align_utils.py:22: RuntimeWarning: At least one epoch has multiple events. Only the latency of the first event will be retained.\n",
      "  tmp = mne.io.read_epochs_eeglab(path)\n",
      "/Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/utils/align_utils.py:26: RuntimeWarning: This filename (/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpo57y3cm1tmp.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  tmp.save(tmpdir+\"tmp.fif\", overwrite=True, verbose=None)\n",
      "/Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/utils/align_utils.py:29: RuntimeWarning: This filename (/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpo57y3cm1tmp.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  return mne.read_epochs(tmpdir+\"tmp.fif\")\n",
      "/Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/utils/align_utils.py:22: RuntimeWarning: At least one epoch has multiple events. Only the latency of the first event will be retained.\n",
      "  tmp = mne.io.read_epochs_eeglab(path)\n",
      "/Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/utils/align_utils.py:26: RuntimeWarning: This filename (/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpbjz6lkextmp.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  tmp.save(tmpdir+\"tmp.fif\", overwrite=True, verbose=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpbjz6lkextmp.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     998.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "206 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoubou/Documents/Work/NYU/Brito-Lab/FINS-Codes/utils/align_utils.py:29: RuntimeWarning: This filename (/var/folders/vv/stc9rswn5c95vxdzpx7z6qqr0000gn/T/tmpbjz6lkextmp.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  return mne.read_epochs(tmpdir+\"tmp.fif\")\n"
     ]
    }
   ],
   "source": [
    "eeg1 = align_utils.EpochsEEGLAB_to_mneEpochsFIF('{}{}_{}_FP/{}'.format(data_path, dy[0], 'child', dy[1])) \n",
    "eeg2 = align_utils.EpochsEEGLAB_to_mneEpochsFIF('{}{}_{}_FP/{}'.format(data_path, dy[0], 'adult', dy[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many epochs we have per EEG file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG-1 has 159 epochs.\n",
      "EEG-2 has 206 epochs.\n"
     ]
    }
   ],
   "source": [
    "print('EEG-1 has {} epochs.'.format(eeg1.get_data().shape[0]))\n",
    "print('EEG-2 has {} epochs.'.format(eeg2.get_data().shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, there should be the same amount of epochs in each file. Moreover, when looking at the index of each epochs (see the x-axis of the plots bellow) we can see that they are all continuous, thus, not indicating which epochs were rejected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg2.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the plan now?\n",
    "\n",
    "When loading an file in the EEGLAB format,  You have the following epoch indeces in your preprocessed file: \n",
    "\n",
    "`1, 2, 3, 4, 5, 6, 7`\n",
    "\n",
    "And you know that the following epochs were rejected:\n",
    "\n",
    "`3, 7, 8`\n",
    "\n",
    "but then get \n",
    "\n",
    "`1, 2, 3, 4`\n",
    "\n",
    "We'll now reconstruct the original epoch index as follows? (Within brackets):\n",
    "\n",
    "`1(1), 2(2), NaN, 4(3), 5(4), 6(5), NaN, NaN, 9(6), 10(7)`\n",
    "\n",
    "\n",
    "> **Careful, we have multiple round of rejection, so that method will have to be iterated over each round.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = eeg1.to_data_frame()\n",
    "df2 = eeg2.to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eeg1epochsIDs = df1.epoch.unique()\n",
    "Eeg2epochsIDs = df2.epoch.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 (2 rounds of preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letters</th>\n",
       "      <th>indeces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letters  indeces\n",
       "0       A        0\n",
       "1       B        1\n",
       "2       C        2\n",
       "3       D        3\n",
       "4       E        4\n",
       "5       F        5\n",
       "6       G        6\n",
       "7       H        7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Letters': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'], 'indeces': [0, 1, 2, 3, 4, 5, 6, 7]})\n",
    "\n",
    "# pd.set_option('display.max_rows', len(state_dict))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letters</th>\n",
       "      <th>indeces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letters  indeces\n",
       "0       A        0\n",
       "2       C        1\n",
       "4       E        2\n",
       "5       F        3\n",
       "6       G        4\n",
       "7       H        5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we remove two rows in a first round:\n",
    "# Create a list of elements to remove\n",
    "rmed_1 = [1, 3]\n",
    "\n",
    "# Create a boolean mask indicating which rows to keep\n",
    "mask = df['indeces'].isin(rmed_1)\n",
    "\n",
    "# Remove the rows that match the elements in the list\n",
    "df.drop(index=df[mask].index, inplace=True)\n",
    "\n",
    "# Now we reset the index the same way saving this 'eeg' file would when being read for the next iteration's round \n",
    "df.indeces = [i for i in range(len(df))]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letters</th>\n",
       "      <th>indeces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letters  indeces\n",
       "2       C        0\n",
       "5       F        1\n",
       "6       G        2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now were remove three rows and directly reset the indeces\n",
    "# Create a list of elements to remove\n",
    "rmed_2 = [2, 5, 0]\n",
    "\n",
    "# Create a boolean mask indicating which rows to keep\n",
    "mask = df['indeces'].isin(rmed_2)\n",
    "\n",
    "# Remove the rows that match the elements in the list\n",
    "df.drop(index=df[mask].index, inplace=True)\n",
    "\n",
    "df.indeces = [i for i in range(len(df))]\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alrigth, now we have two list containning the indeces that were removed **`at the time of their round of rejection`**. \n",
    "\n",
    "Keep in mind that the index #4 could be deleted in multiple round as #4 could be reassigned when the file is re-read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index that were rejected at the\n",
      "\t1st round: [1, 3]\n",
      "\t2st round: [2, 5, 0]\n",
      "The indeces as they are after the last rejection round [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "final_idx = df['indeces'].tolist()\n",
    "print('Index that were rejected at the\\n\\t1st round: {}\\n\\t2st round: {}'.format(rmed_1, rmed_2))\n",
    "print('The indeces as they are after the last rejection round {}'.format(final_idx))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the list of epochs that were rejected as the `list` of `list` containing the IDs of the epochs that were rejected at each round of preprocessing. **The first `list` should contain the epochs IDs rejected at first preprocessing round and the last element should correspond to the last.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3], [2, 5, 0]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the list of epochs that were rejected\n",
    "rmed_list=[rmed_1, rmed_2]\n",
    "rmed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state:\n",
      "\t 0 0\n",
      "\t 1 1\n",
      "\t 2 2\n",
      "Updated state:\n",
      "\t 0 NaN\n",
      "\t 1 0\n",
      "\t 2 NaN\n",
      "\t 3 1\n",
      "\t 4 2\n",
      "\t 5 NaN\n",
      "Updated state:\n",
      "\t 0 NaN\n",
      "\t 2 0\n",
      "\t 4 NaN\n",
      "\t 5 1\n",
      "\t 6 2\n",
      "\t 7 NaN\n",
      "\t 1 NaN\n",
      "\t 3 NaN\n"
     ]
    }
   ],
   "source": [
    "updated_state_dict = align_utils.revert_to_original_idx(\n",
    "    last_state = final_idx,\n",
    "    removed_list  = rmed_list,\n",
    "    verbose    = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that we reconstructed the correspondance between IDs and their original place correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tOriginal ID\tFinal state\tLetter\n",
      "\t 0 \t\t NaN \t\t A\n",
      "\t 1 \t\t NaN \t\t B\n",
      "\t 2 \t\t 0 \t\t C\n",
      "\t 3 \t\t NaN \t\t D\n",
      "\t 4 \t\t NaN \t\t E\n",
      "\t 5 \t\t 1 \t\t F\n",
      "\t 6 \t\t 2 \t\t G\n",
      "\t 7 \t\t NaN \t\t H\n"
     ]
    }
   ],
   "source": [
    "letters=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "\n",
    "tt = sorted(updated_state_dict.keys())\n",
    "\n",
    "print('\\tOriginal ID\\tFinal state\\tLetter',)\n",
    "for i in tt:\n",
    "    print('\\t',i,'\\t\\t',updated_state_dict[i],'\\t\\t', letters[i])  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! We've rebuilt the connection between the indeces that were given post preprocessing (above, the column 'Original ID')and the ones we got (the 'Final state' column).\n",
    "\n",
    "We now have a dictionnary that has `keys` representing each of the original epoch ID and `values` representing the state of that epoch at the end of preprocessing.\n",
    "\n",
    "The **state** can be either\n",
    "- `NaN` which indicated that this epoch was removed during preprocessing **or,**\n",
    "- the id that was initially associated to the remaining epochs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 (3 rounds of preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df2: original\n",
      "   Letters  indeces\n",
      "0       A        0\n",
      "1       B        1\n",
      "2       C        2\n",
      "3       D        3\n",
      "4       E        4\n",
      "5       F        5\n",
      "6       G        6\n",
      "7       H        7\n",
      "\n",
      "df2: 1st round of rejection\n",
      "   Letters  indeces\n",
      "0       A        0\n",
      "2       C        1\n",
      "3       D        2\n",
      "5       F        3\n",
      "6       G        4\n",
      "7       H        5\n",
      "\n",
      "df2: 2nd round of rejection\n",
      "   Letters  indeces\n",
      "2       C        0\n",
      "3       D        1\n",
      "5       F        2\n",
      "6       G        3\n",
      "7       H        4\n",
      "\n",
      "df2: 3rd round of rejection\n",
      "   Letters  indeces\n",
      "2       C        0\n",
      "3       D        1\n",
      "5       F        2\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame({'Letters': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'], 'indeces': [0, 1, 2, 3, 4, 5, 6, 7]})\n",
    "print('df2: original\\n', df2)\n",
    "\n",
    "rmed_1_2 = [1, 4]\n",
    "df2.drop(index=df2[df2['indeces'].isin(rmed_1_2)].index, inplace=True)\n",
    "df2.indeces = [i for i in range(len(df2))]\n",
    "print('\\ndf2: 1st round of rejection\\n', df2)\n",
    "\n",
    "rmed_2_2 = [0]\n",
    "df2.drop(index=df2[df2['indeces'].isin(rmed_2_2)].index, inplace=True)\n",
    "df2.indeces = [i for i in range(len(df2))]\n",
    "print('\\ndf2: 2nd round of rejection\\n', df2)\n",
    "\n",
    "rmed_3_2 = [3, 4]\n",
    "df2.drop(index=df2[df2['indeces'].isin(rmed_3_2)].index, inplace=True)\n",
    "df2.indeces = [i for i in range(len(df2))]\n",
    "print('\\ndf2: 3rd round of rejection\\n', df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_state_dict_2 = align_utils.revert_to_original_idx(\n",
    "    last_state = df2['indeces'].tolist(),\n",
    "    removed_list  = [rmed_1_2, rmed_2_2, rmed_3_2],\n",
    "    verbose    = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tOriginal ID\tFinal state\tLetter\n",
      "\t 0 \t\t NaN \t\t A\n",
      "\t 1 \t\t NaN \t\t B\n",
      "\t 2 \t\t 0 \t\t C\n",
      "\t 3 \t\t 1 \t\t D\n",
      "\t 4 \t\t NaN \t\t E\n",
      "\t 5 \t\t 2 \t\t F\n",
      "\t 6 \t\t NaN \t\t G\n",
      "\t 7 \t\t NaN \t\t H\n"
     ]
    }
   ],
   "source": [
    "print('\\tOriginal ID\\tFinal state\\tLetter',)\n",
    "for i in sorted(updated_state_dict_2.keys()):\n",
    "    print('\\t',i,'\\t\\t',updated_state_dict_2[i],'\\t\\t', letters[i])  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding concurrent epochs from "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now we have 2 dictionnary containing as keys the original epochs index, and as values, the `last state`. I.e., either `NaN` if the epoch was removed **or** the latest index given to this epoch post-preprocessing. \n",
    "\n",
    "We're now going to see which paris of concurrent epochs are still available in each set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'NaN', 2: 0, 4: 'NaN', 5: 1, 6: 2, 7: 'NaN', 1: 'NaN', 3: 'NaN'}\n",
      "{2: 0, 3: 1, 5: 2, 6: 'NaN', 7: 'NaN', 0: 'NaN', 1: 'NaN', 4: 'NaN'}\n"
     ]
    }
   ],
   "source": [
    "print(updated_state_dict)\n",
    "print(updated_state_dict_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we convert these dictionnary to pd.df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LastState-1\n",
      "0         NaN\n",
      "1         NaN\n",
      "2           0\n",
      "3         NaN\n",
      "4         NaN\n",
      "5           1\n",
      "6           2\n",
      "7         NaN \n",
      "\n",
      "   LastState-2\n",
      "0         NaN\n",
      "1         NaN\n",
      "2           0\n",
      "3           1\n",
      "4         NaN\n",
      "5           2\n",
      "6         NaN\n",
      "7         NaN\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame.from_dict(\n",
    "    updated_state_dict, \n",
    "    orient='index', \n",
    "    columns=['LastState-1']).sort_index()\n",
    "df1.replace('NaN', np.nan)\n",
    "\n",
    "df2 = pd.DataFrame.from_dict(\n",
    "    updated_state_dict_2, \n",
    "    orient='index', \n",
    "    columns=['LastState-2']).sort_index()\n",
    "df2.replace('NaN', np.nan)\n",
    "\n",
    "print(df1, '\\n\\n', df2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then, we merge these `LastState` columns in the same `comparaisonDf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LastState-1</th>\n",
       "      <th>LastState-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LastState-1 LastState-2\n",
       "0         NaN         NaN\n",
       "1         NaN         NaN\n",
       "2           0           0\n",
       "3         NaN           1\n",
       "4         NaN         NaN\n",
       "5           1           2\n",
       "6           2         NaN\n",
       "7         NaN         NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparaisonDf = df1.join(df2[\"LastState-2\"])\n",
    "comparaisonDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful references"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To get comfortable with the MNE documentation, you should know that MNE is based on python [Object Oriented Programming (00P)](hstate_dictps://realpython.com/python3-object-oriented-programming/). These objects are defined from a python `Class`.\n",
    "    - You can get familiarized with the OOP structure and its componenent, e.g. `methods` (a function associated to the the object) and `astate_dictribute` (a variable associated to the object), wit [this tutorial](hstate_dictps://www.datacamp.com/tutorial/python-oop-tutorial).\n",
    "    - In MNE, we find [`Raw` objects](hstate_dictps://mne.tools/stable/generated/mne.io.Raw.html) (continuous data) or [`Epoch` objects](hstate_dictps://mne.tools/stable/generated/mne.Epochs.html) (a collection of epochs). \n",
    "\n",
    "You can find an introduction to the **Epochs data structure** [here](hstate_dictps://mne.tools/stable/auto_tutorials/epochs/10_epochs_overview.html) in MNE. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the epoch data\n",
    "\n",
    "We're now going to extract the epoch data from the mne.EpochFIF to apply the operation described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d93afb8cdc34b2bdea5bf079bccd93013ea04d457e334f9ae90fb664fbdee86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
